# AI Agent Guide for Chemistry 101 Training Suite

## Overview
This guide explains how the reinforcement learning (RL) system works, how attention mechanisms enhance learning, and how weights and biases function within the chemistry AI training suite.

## Reinforcement Learning Architecture

### Core RL Components
The system uses a value-based RL approach where each vocabulary term has associated learnable parameters:
- `weight`: Primary attention weight (influences prediction likelihood)
- `bias[4]`: Bias terms that adjust prediction based on context
- `score`: RL reward signal that tracks learning progress

### Learning Cycle
1. **Prediction Phase**: AI predicts answer using current weights
2. **Evaluation Phase**: Compare prediction with correct answer
3. **Update Phase**: Adjust weights based on correctness
   - Correct answer: `score += reward_factor` (default 0.1)
   - Incorrect answer: `score -= penalty_factor` (default 0.05)

## Attention Mechanism Integration

### Without Attention (Basic RL)
- Prediction based solely on vocabulary weights
- `score = vocab_weight * context_match`
- Limited to direct term matching in questions

### With Attention (Enhanced RL)
- Uses query, context, and value weights for sophisticated matching
- `score = (prefix_match * query_weight + suffix_match * context_weight) * vocab_weight * (1 + score)`
- Attention values: `score += value_weight * embedding_magnitude`

### Attention Components
- `context_weights`: How well vocabulary term matches question context
- `query_weights`: How well vocabulary term fits what's being asked
- `value_weights`: Inherent importance of the vocabulary term

## Weight and Bias Functions

### Weight Parameters
- `embedding[2]`: 2D position in semantic space (fixed)
- `weight`: Primary attention strength (0.0-1.0 range, adjusted by RL)
- `score`: Accumulated RL reward (-inf to +inf, influences predictions)

### Bias Parameters
- `bias[0]`: Context position bias (early/late in sentence)
- `bias[1]`: Question type bias (definition vs application questions)
- `bias[2]`: Difficulty bias (basic vs advanced terms)
- `bias[3]`: Frequency bias (common vs rare terms)

## Manual Weight Tuning

### When to Manually Adjust Weights
- AI consistently makes the same mistakes
- Vocabulary terms that should be prioritized for pedagogical reasons
- Terms that aren't being used in context despite being correct
- After analyzing learning patterns in comparison_tool output

### Manual Adjustment Guidelines

#### Adjusting Primary Weight
- **Increase**: For fundamental concepts that should be recalled frequently
- **Decrease**: For advanced concepts that are over-predicted
- **Range**: 0.0 (never selected) to 1.0 (highly prioritized)

#### Adjusting Bias Terms
- `bias[0]`: Increase for terms likely to appear early in answers
- `bias[1]`: Increase for definition terms, decrease for application terms
- `bias[2]`: Increase for basic terms, decrease for advanced terms
- `bias[3]`: Increase for high-frequency terms

### Example Manual Adjustments

#### Scenario 1: Improving Atomic Structure Understanding
```
# Before: proton -0.8 0.5 0.3 0.1 0.2 -0.1 0.4 0.2
# After:  proton -0.8 0.5 0.9 0.1 0.2 -0.1 0.4 0.2
# (Increased primary weight from 0.3 to 0.9)
```

#### Scenario 2: Balancing Advanced vs Basic Terms
```
# Reduce over-prediction of advanced term
# Before: quantum_mechanics 0.4 -0.3 0.8 -0.2 0.3 0.1 0.7 -0.1
# After:  quantum_mechanics 0.4 -0.3 0.4 -0.2 0.3 0.1 0.7 -0.1
# (Reduced primary weight from 0.8 to 0.4)
```

## RL Algorithm Details

### Reward Structure
```
if prediction_correct:
    vocabulary_term.score += 0.1  # Positive reinforcement
    # Also consider: increase related terms' scores
else:
    vocabulary_term.score -= 0.05 # Gentle penalty
    # Also consider: decrease competing terms' scores
```

### Context Matching
The system evaluates how well each vocabulary term fits the question context:
```c
// Simplified context matching
float prefix_match = (strstr(prefix, vocab.word) != NULL) ? 1.0f : 0.1f;
float suffix_match = (strstr(suffix, vocab.word) != NULL) ? 1.0f : 0.1f;
float attention_score = (prefix_match + suffix_match) * vocab.weight * (1.0f + vocab.score);
```

## Attention Mechanism Deep Dive

### Query-Context-Value Architecture
1. **Query**: What the question is asking for
2. **Context**: The surrounding text of the question
3. **Value**: The inherent importance of the vocabulary term

### Attention Weight Updates
```
if correct_answer_selected:
    attention.query_weights[vocab_idx] += 0.05
    attention.context_weights[vocab_idx] += 0.05
    attention.value_weights[vocab_idx] += 0.05
else:
    attention.query_weights[vocab_idx] -= 0.01
    attention.context_weights[vocab_idx] -= 0.01
    attention.value_weights[vocab_idx] -= 0.01
```

### Attention Normalization
Weights are clamped to prevent runaway values:
- Minimum: 0.0 (no influence)
- Maximum: 1.0 (maximum influence)

## Training Progression

### Early Training Phase
- RL scores near zero
- Predictions based primarily on initial weights
- High variance in predictions

### Mid Training Phase
- RL scores begin to differentiate
- Attention mechanisms become more refined
- More consistent predictions

### Late Training Phase
- Well-calibrated scores based on performance history
- Sophisticated attention patterns
- Optimized for specific question types

## Performance Optimization Tips

### Improving Prediction Accuracy
1. Ensure balanced vocabulary weights (not all terms have similar weights)
2. Fine-tune bias terms based on common mistake patterns
3. Monitor attention weights for context matching improvements

### Managing Learning Speed
- **Faster learning**: Increase reward/penalty magnitudes
- **Stable learning**: Decrease reward/penalty magnitudes
- **Focus learning**: Increase weights of targeted concepts

## Troubleshooting Common Issues

### Issue: AI Always Predicts Same Terms
**Cause**: Unbalanced weights or poor attention training  
**Solution**: Decrease dominant term weights, increase weights of underutilized terms

### Issue: No Learning Progress
**Cause**: Small reward magnitudes or poor context matching  
**Solution**: Increase reward/penalty factors, verify embedding quality

### Issue: Overfitting to Specific Questions
**Cause**: Over-tuned attention weights  
**Solution**: Reduce attention learning rate, add diversity in training questions

## Integration with Existing LLM
The system can be enhanced by incorporating the existing LLM from `3.stage.llm]...` directory:
- Use LLM for more sophisticated context analysis
- Enhance attention mechanisms with transformer-style attention
- Implement more complex RL reward structures
- Enable few-shot learning capabilities